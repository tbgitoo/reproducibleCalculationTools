p_matrix
get_p_value_estimate(x,T0,T,N_per_condition)
get_p_value_estimate<-function(x,T0,T,N_per_condition)#
{#
#
theory_reaction_rate = matrix(nrow=length(x),ncol=length(T))#
# In reality, we would dispose of measured values with variability rather than theoretical values. Let's say we dispose of 15 values for theoretical value#
measured=data.frame(T=vector(mode="numeric",length=0),x=vector(mode="numeric",length=0),measured_reaction_rate=vector(mode="numeric",length=0))#
for(ind_x in 1:length(x))#
{#
	for(ind_T in 1:length(T))#
	{#
		theory_reaction_rate[ind_x,ind_T]=50*exp(-T0[ind_x]/T[ind_T])#
		# Let's say we have normal distribution at log scale#
		# Generate a random sample with 15 values#
		measurements_random =exp(log(theory_reaction_rate[ind_x,ind_T])+rnorm(N_per_condition))#
		measured=rbind(measured,data.frame(T=T[ind_T],x=x[ind_x],measured_reaction_rate=measurements_random))#
	}#
}#
#
# For the evaluation, let's first evaluate things globally. Let's say we are interested in knowing for each catalyst concentration x the temperature where the reaction rate is half-maximal. We estimate the maximum reaction rate at the highest temperature:#
#
v_max = aggregate ( measured_reaction_rate ~ x, measured[measured$T==max(measured$T),],FUN=median,na.rm=TRUE)#
# General aggregation per x and T#
v = aggregate(measured_reaction_rate ~ x+T,measured,FUN=median,na.rm=TRUE)#
overall_summary=estimate_half_temperature_at_half_maximal_rate(v)#
pvals=vector(length=2, mode="numeric")#
#
names(pvals)=c("lm","lm bootstrapping")#
#
pvals["lm"]=coefficients(summary(lm(log(half_temperature)~x, overall_summary)))["x","Pr(>|t|)"]#
#
n_agg = 3 # Let's generate three subsampling plots#
N_total = n_agg*100 # 100 blocks#
n_to_sample = round(N_per_condition/n_agg) # Nominal coverage of 1#
#
y=matrix(nrow=length(x),ncol=N_total)#
#
for(ind_bootstrap in 1:N_total)#
{#
#
measured_subsampled=measured[FALSE,]#
#
for(ind_x in 1:length(x))#
{#
	for(ind_T in 1:length(T))#
	{#
		to_subsample = measured[measured$T==T[ind_T] & measured$x==x[ind_x],]#
		measured_subsampled=rbind(measured_subsampled,to_subsample[sample(dim(to_subsample)[1], n_to_sample),])#
	}#
}#
#
v_subsampled=aggregate(measured_reaction_rate ~ x+T,measured_subsampled,FUN=median,na.rm=TRUE)#
#
half_temperature_estimate=estimate_half_temperature_at_half_maximal_rate(v_subsampled)#
#
y[match(half_temperature_estimate$x,x),ind_bootstrap]=half_temperature_estimate$half_temperature#
#
}#
#
# x is now the regressor values (catalyst concentrations) as wanted#
#
pvals["lm bootstrapping"]=linear_regression_p_bootstrap(x,log(y),n_agg=n_agg,na.rm=TRUE)#
#
return(pvals)#
#
}
get_p_value_estimate(x,T0,T,N_per_condition)
# First, the case with a known effect#
x=c(0,2,4) # Concentrations catalyst#
T0=exp(x) # Let's say, this is an exponential dependency#
T=c(1,3,10,30,100,300,1000) # Known temperatures#
N_per_condition=15#
N_simulation=20#
pfirst=get_p_value_estimate(x,T0,T,N_per_condition)
pfirst
pfirst=get_p_value_estimate(x,T0,T,N_per_condition)#
#
p_matrix=matrix(ncol=length(pfirst),nrow=N_simulation)#
#
p_matrix[1,]=pfirst#
#
colnames(p_matrix)=names(pfirst)#
#
for(ind in 2:(dim(p_matrix)[1]))#
{#
	p_matrix[ind,]=get_p_value_estimate(x,T0,T,N_per_condition)#
	cat(paste("Run ", ind, "\n", sep=""))#
#
}
p_matrix
power=pfirst#
for(theApproach in names(power))#
{#
	current_data=p_matrix[,theApproach]#
	current_data=current_data[!is.na(current_data)]#
	power[theApproach]=sum(current_data<=0.05)/(length(current_data))#
}
power
# First, the case with a known effect#
x=c(0,2,4) # Concentrations catalyst#
T0=exp(x) # Let's say, this is an exponential dependency#
T=c(1,3,10,30,100,300,1000) # Known temperatures#
N_per_condition=15#
N_simulation=100#
pfirst=get_p_value_estimate(x,T0,T,N_per_condition)#
#
p_matrix=matrix(ncol=length(pfirst),nrow=N_simulation)#
#
p_matrix[1,]=pfirst#
#
colnames(p_matrix)=names(pfirst)#
#
for(ind in 2:(dim(p_matrix)[1]))#
{#
	p_matrix[ind,]=get_p_value_estimate(x,T0,T,N_per_condition)#
	cat(paste("Run ", ind, "\n", sep=""))#
#
}#
power=pfirst#
for(theApproach in names(power))#
{#
	current_data=p_matrix[,theApproach]#
	current_data=current_data[!is.na(current_data)]#
	power[theApproach]=sum(current_data<=0.05)/(length(current_data))#
}#
# Second, false positives#
T0=exp(0*x) # No effect of the catalyst#
pfirst=get_p_value_estimate(x,T0,T,N_per_condition)#
#
p_matrix_control=matrix(ncol=length(pfirst),nrow=N_simulation)#
#
p_matrix_control[1,]=pfirst#
#
colnames(p_matrix_control)=names(pfirst)#
#
for(ind in 2:(dim(p_matrix_control)[1]))#
{#
	p_matrix_control[ind,]=get_p_value_estimate(x,T0,T,N_per_condition)#
	cat(paste("Run ", ind, "\n", sep=""))#
#
}#
false_positives=pfirst#
for(theApproach in names(false_positives))#
{#
	current_data=p_matrix_control[,theApproach]#
	current_data=current_data[!is.na(current_data)]#
	false_positives[theApproach]=sum(current_data<=0.05)/(length(current_data))#
}#
#
for_barplot=matrix(nrow=2,ncol=length(false_positives),data=c(false_positives, power),byrow=TRUE)#
#
rownames(for_barplot)=c("False positives (alpha)", "True positives (1-beta, power)")#
colnames(for_barplot)=names(false_positives)#
#
barplot(for_barplot,beside=TRUE,legend=TRUE)
for_barplot
rm(list=ls())
load("~/Downloads/overview_simulation_jumps_corrected.rda")
ls()
colnames(overview_simulation)
to_look_for=overview_simulation$packing_fraction==1.5 & overview_simulation$Young_modulus_spheres=1e4
to_look_for=overview_simulation$packing_fraction==1.5 & overview_simulation$Young_modulus_spheres==1e4
sum(to_look_for)
to_look_for=overview_simulation$packing_fraction==1.5 & overview_simulation$Young_modulus_spheres==1e4 & overview_simulation$Strain_amplitude==0.1
sum(to_look_for)
to_look_for=overview_simulation$packing_fraction==1.5 & overview_simulation$Young_modulus_spheres==1e4 & overview_simulation$Strain_amplitude==0.1 & overview_simulation $do_permanent_links==1
sum(to_look_for)
to_look_for=overview_simulation$packing_fraction==1.5 & overview_simulation$Young_modulus_spheres==1e4 & overview_simulation$Strain_amplitude==0.1 & overview_simulation $do_permanent_links==1 & overview_simulation$remove_link_fraction==0.4
sum(to_look_for)
to_look_for=overview_simulation$packing_fraction==1.5 & overview_simulation$Young_modulus_spheres==1e4 & overview_simulation$Strain_amplitude==0.1 & overview_simulation $do_permanent_links==1 & overview_simulation$remove_link_fraction==0.4 & overview_simulation$cut_lines==5
sum(to_look_for)
overview_simulation[to_look_for,]
to_look_for=overview_simulation$packing_fraction==1.5 & overview_simulation$Young_modulus_spheres==1e4 & overview_simulation$Strain_amplitude==0.1 & overview_simulation $do_permanent_links==1 & overview_simulation$remove_link_fraction==0.4 & overview_simulation$cut_lines==5 & overview_simulation$Friction_coefficient==0.1
sum(to_look_for)
overview_simulation[to_look_for,]
to_look_for=overview_simulation$packing_fraction==1.5 & overview_simulation$Young_modulus_spheres==1e4 & overview_simulation$Strain_amplitude==0.1 & overview_simulation $do_permanent_links==1 & overview_simulation$remove_link_fraction==0.6 & overview_simulation$cut_lines==5 & overview_simulation$Friction_coefficient==0.1
sum(to_look_for)
to_look_for=overview_simulation$packing_fraction==1.5 & overview_simulation$Young_modulus_spheres==1e4 & overview_simulation$Strain_amplitude==0.1 & overview_simulation $do_permanent_links==1 & overview_simulation$remove_link_fraction==0.5 & overview_simulation$cut_lines==5 & overview_simulation$Friction_coefficient==0.1
sum(to_look_for)
unique(overview_simulation$remove_link_fraction)
library(particleShearEvaluation)
strain=c(0.01,0.03,0.1,0.3,1,3,10)#
Gprime=c(1000,950,700,300,100,20,10)#
Gprimeprime=c(50,60,80,100,120,110,50)#
get_yield_point(strain,Gprime,Gprimeprime)
strain=c(0.01,0.03,0.1,0.3,1,3,10)#
Gprime=c(1000,950,700,300,100,20,10)#
Gprimeprime=c(50,60,80,100,120,110,50)#
plot(Gprime ~ strain)#
lines(Gprimeprime ~ strain)#
get_yield_point(strain,Gprime,Gprimeprime)
strain=c(0.01,0.03,0.1,0.3,1,3,10)#
Gprime=c(1000,950,700,300,100,20,10)#
Gprimeprime=c(50,60,80,100,120,110,50)#
plot(Gprime ~ strain)#
lines(Gprimeprime ~ strain)#
lines(rep(get_yield_point(strain,Gprime,Gprimeprime),2),c(0,max(Gprime)))
strain=c(0.01,0.03,0.1,0.3,1,3,10)#
Gprime=c(1000,950,700,300,100,20,10)#
Gprimeprime=c(50,60,80,100,120,110,50)#
plot(Gprime ~ strain,type="b")#
lines(Gprimeprime ~ strain)#
lines(rep(get_yield_point(strain,Gprime,Gprimeprime),2),c(0,max(Gprime)))
strain=c(0.01,0.03,0.1,0.3,1,3,10)#
Gprime=c(1000,950,700,300,100,20,10)#
Gprimeprime=c(50,60,80,100,120,110,50)#
plot(Gprime ~ strain,type="b")#
lines(Gprimeprime ~ strain)#
lines(rep(get_yield_point(strain,Gprime,Gprimeprime),2),c(0,max(Gprime)),lty=2)
strain=c(0.01,0.03,0.1,0.3,1,3,10)#
Gprime=c(1000,950,700,300,100,20,10)#
Gprimeprime=c(50,60,80,100,120,110,50)#
plot(Gprime ~ strain,type="b",ylab=c("G' and G''"))#
lines(Gprimeprime ~ strain)#
lines(rep(get_yield_point(strain,Gprime,Gprimeprime),2),c(0,max(Gprime)),lty=2)
strain=c(0.01,0.03,0.1,0.3,1,3,10)#
Gprime=c(1000,950,700,300,100,20,10)#
Gprimeprime=c(50,60,80,100,120,110,50)#
plot(Gprime ~ strain,type="b",ylab=c("G' and G''"))#
lines(Gprimeprime ~ strain)#
lines(rep(get_yield_point(strain,Gprime,Gprimeprime),2),c(0,max(Gprime)),lty=2)#
get_yield_point(strain,Gprime,Gprimeprime)
system
system.path
help(system.file)
system.file("full_python_simulation_output_example.txt",package="particleShearEvaluation")
4*60/75*1000
3*60/75*1000
read_general_data_from_file{system.file("full_python_simulation_output_example.txt",package="particleShearEvaluation")}
read_general_data_from_file(system.file("full_python_simulation_output_example.txt",package="particleShearEvaluation"))
read_general_data_from_file
general_data=read_general_data_from_file(system.file("full_python_simulation_output_example.txt",package="particleShearEvaluation"))
general_data
general_data=read_general_data_from_file(system.file("full_python_simulation_output_example.txt",package="particleShearEvaluation"))#
general_data[71:78]
stress_curve=read_stress_curve_from_file(system.file("full_python_simulation_output_example.txt",package="particleShearEvaluation"))
colnames(stress_curve)
plot(strain ~ t, stress_curve)
stress_curve=read_stress_curve_from_file(system.file("full_python_simulation_output_example.txt",package="particleShearEvaluation"))#
plot(strain ~ t, stress_curve,type="l",xlab="t[s]",ylab="strain [-]")
plot(shear_stress_from_internal_stress_tensor ~ t, stress_curve,type="l")
plot(strain ~ t, stress_curve,type="l",xlab="t[s]",ylab="strain [-]")#
lines(stress_curve$t, stress_curve$shear_stress_from_internal_stress_tensor/1000,type="l",col="red")
plot(strain ~ t, stress_curve,type="l",xlab="t[s]",ylab="strain [-], stress[kPa]")#
lines(stress_curve$t, stress_curve$shear_stress_from_internal_stress_tensor/1000,type="l",col="red")
plot(strain ~ t, stress_curve,type="l",xlab="t[s]",ylab="strain [-], stress[kPa]")#
lines(stress_curve$t, stress_curve$shear_stress_from_internal_stress_tensor/1000,type="l",col="red")#
legend("bottomleft",legend=c("strain","stress"),lty=c(1,1),col=c("black","red"))
getwd()
library(particleShearEvaluation)
system.file(".",package="particleShearEvaluation")
system.file("",package="particleShearEvaluation")
nchar("")
nchar("/")
help(substr)
destination_root="/Library/Frameworks/R.framework/Versions/4.0/Resources/library/particleShearEvaluation/"
destination_root
nchar(destination_root)
substr(destination_root,nchar(destination_root)-1,nchar(destination_root) )
substr(destination_root,nchar(destination_root),nchar(destination_root)+1 )
substr(destination_root,nchar(destination_root),nchar(destination_root) )
substr(destination_root,nchar(destination_root),nchar(destination_root)-1 )
substr(destination_root,nchar(destination_root)-1,nchar(destination_root) )
substr(destination_root,nchar(destination_root),nchar(destination_root) )
help(substr)
substr(destination_root,nchar(destination_root),nchar(destination_root))=="/"
substr(destination_root,0,nchar(destination_root))
substr(destination_root,0,nchar(destination_root)-1)
path="/particleShearEvaluation"
orign_root=""/Library/Frameworks/R.framework/Versions/4.0/Resources/library/"
orign_root="/Library/Frameworks/R.framework/Versions/4.0/Resources/library/"
origin_root="/Library/Frameworks/R.framework/Versions/4.0/Resources/library/"
if(nchar(origin_root)>1)#
    {#
        if(substr(origin_root,nchar(origin_root),nchar(origin_root))=="/")#
        {#
            origin_root=substr(origin_root,0,nchar(origin_root)-1)#
        }#
    }
origin_root
path
path="/particleShearEvaluation/"
if(nchar(path)>1)#
    {#
        if(substr(path,nchar(path),nchar(path))=="/")#
        {#
            path=substr(path,0,nchar(path)-1)#
        }#
    }
path
substr(path,0,0)
substr(path,0,1)
substr(path,1,nchar(path))
substr(path,2,nchar(path))
substr(path,1,1)
substr(path,1,2)
substr(path,1,1)
system.file(".",package="particleShearEvaluation")
system.file("",package="particleShearEvaluation")
split_tensor_and_overview_data(origin_root=system.file("",package="particleShearEvaluation"),path="","full_python_simulation_output_example.txt")
library(particleShearEvaluation)
split_tensor_and_overview_data(origin_root=system.file("",package="particleShearEvaluation"),path="","full_python_simulation_output_example.txt")
library(particleShearEvaluation)
split_tensor_and_overview_data(origin_root=system.file("",package="particleShearEvaluation"),path="","full_python_simulation_output_example.txt")
split_tensor_and_overview_data(origin_root=system.file("",package="particleShearEvaluation"),path="","full_python_simulation_output_example.txt",overwrite=TRUE)
getwd()
help(save)
split_tensor_and_overview_data(origin_root=system.file("",package="particleShearEvaluation"),path="","full_python_simulation_output_example.txt")
library(particleShearEvaluation)
system.file("split",package="particleShearEvaluation")
system.file("split/stress_full_python_simulation_output_example.rda",package="particleShearEvaluation")
path=system.file("split/stress_full_python_simulation_output_example.rda",package="particleShearEvaluation")#
stress_curve=read_stress_curve_from_rda_file(path)
colnames(stress_curve)
plot(strain ~ t, stress_curve,type="l",xlab="t[s]",ylab="strain [-], stress[kPa]")#
lines(stress_curve$t, stress_curve$shear_stress_from_internal_stress_tensor/1000,type="l",col="red")#
legend("bottomleft",legend=c("strain","stress"),lty=c(1,1),col=c("black","red"))
path=system.file("full_python_simulation_output_example.txt",package="particleShearEvaluation")
path
path=system.file("full_python_simulation_output_example.txt",package="particleShearEvaluation")#
stress_tensor_data=read_stress_tensor_data_from_file(path)
dim(stress_tensor_data)
colnames(stress_tensor_data)
stress_tensor_data$index[1:10]
read_stress_tensor_data_from_file
help(data.frame)
stress_tensor_symmetry_Love_Weber=stress_tensor_data$stress_tensor_Love_Weber_01-stress_tensor_data$stress_tensor_Love_Weber_10#
plot(stress_tensor_data$t,stress_tensor_symmetry_Love_Weber)
stress_tensor_symmetry_Love_Weber=stress_tensor_data$stress_tensor_Love_Weber_01-stress_tensor_data$stress_tensor_Love_Weber_10#
plot(stress_tensor_data$t,stress_tensor_symmetry_Love_Weber,type="l")
stress_tensor_symmetry_Love_Weber=stress_tensor_data$stress_tensor_Love_Weber_01-stress_tensor_data$stress_tensor_Love_Weber_10#
plot(stress_tensor_data$t,stress_tensor_symmetry_Love_Weber,type="l", ylim=c(-20,20))
stress_tensor_symmetry_Love_Weber=stress_tensor_data$stress_tensor_Love_Weber_01-stress_tensor_data$stress_tensor_Love_Weber_10#
plot(stress_tensor_data$t,stress_tensor_symmetry_Love_Weber,type="l", ylim=c(-20,20),main="Asymmetry: Love-Weber",ylab="Stress tensor asymmetry [Pa]")
stress_tensor_symmetry_Otsuki=stress_tensor_data$stress_tensor_peculiar_acceleration_otsuki_01-stress_tensor_data$stress_tensor_peculiar_acceleration_otsuki_10#
plot(stress_tensor_data$t,stress_tensor_symmetry_Otsuki,type="l", ylim=c(-20,20),main="Asymmetry: Otsuki",ylab="Stress tensor asymmetry [Pa]")
stress_tensor_symmetry_Otsuki=stress_tensor_data$stress_tensor_peculiar_acceleration_otsuki_01-stress_tensor_data$stress_tensor_peculiar_acceleration_otsuki_10#
plot(stress_tensor_data$t,stress_tensor_symmetry_Otsuki,type="l", ylim=c(-20,20),main="Asymmetry: Otsuki correction term",ylab="Stress tensor asymmetry [Pa]")
stress_tensor_symmetry_external=stress_tensor_data$stress_tensor_from_external_forces_01-stress_tensor_data$stress_tensor_from_external_forces_10#
plot(stress_tensor_data$t,stress_tensor_symmetry_external,type="l", ylim=c(-20,20),main="Asymmetry: Stress tensor from surface forces",ylab="Stress tensor asymmetry [Pa]")
stress_tensor_symmetry_linear_acceleration=stress_tensor_data$stress_tensor_linear_acceleration_01-stress_tensor_data$stress_tensor_linear_acceleration_10#
plot(stress_tensor_data$t,stress_tensor_linear_acceleration_01,type="l", ylim=c(-20,20),main="Asymmetry: Linear acceleration tensor",ylab="Stress tensor asymmetry [Pa]")
stress_tensor_symmetry_linear_acceleration=stress_tensor_data$stress_tensor_linear_acceleration_01-stress_tensor_data$stress_tensor_linear_acceleration_10#
plot(stress_tensor_data$t,stress_tensor_symmetry_linear_acceleration,type="l", ylim=c(-20,20),main="Asymmetry: Linear acceleration tensor",ylab="Stress tensor asymmetry [Pa]")
stress_tensor_asymmetry_linear_acceleration=stress_tensor_data$stress_tensor_linear_acceleration_01-stress_tensor_data$stress_tensor_linear_acceleration_10#
plot(stress_tensor_data$t,stress_tensor_asymmetry_linear_acceleration,type="l", ylim=c(-20,20),main="Asymmetry: Linear acceleration tensor",ylab="Stress tensor asymmetry [Pa]")
plot(stress_tensor_data$t,stress_tensor_asymmetry_linear_acceleration,type="l", ylim=c(-20,20),main="Asymmetry: Linear acceleration tensor",ylab="Stress tensor asymmetry [Pa]")#
lines(stress_tensor_data$t,stress_tensor_asymmetry_external,type="l",col="red")
path=system.file("full_python_simulation_output_example.txt",package="particleShearEvaluation")#
stress_tensor_data=read_stress_tensor_data_from_file(path)#
# Some of the stress tensors are symmetrical, some not#
#
# The classical Love-Weber tensors are not:#
stress_tensor_asymmetry_Love_Weber=stress_tensor_data$stress_tensor_Love_Weber_01-stress_tensor_data$stress_tensor_Love_Weber_10#
plot(stress_tensor_data$t,stress_tensor_asymmetry_Love_Weber,type="l", ylim=c(-20,20),main="Asymmetry: Love-Weber",ylab="Stress tensor asymmetry [Pa]")#
#
# Otsuki et al. indicate a dynamic symmetry correction; in our experience, this does not correct the problem. The Otsuki correction is indeed orders of magnitude smaller than#
# the asymmetry in the Love-Weber tensor to correct#
dev.new()#
stress_tensor_asymmetry_Otsuki=stress_tensor_data$stress_tensor_peculiar_acceleration_otsuki_01-stress_tensor_data$stress_tensor_peculiar_acceleration_otsuki_10#
plot(stress_tensor_data$t,stress_tensor_asymmetry_Otsuki,type="l", ylim=c(-20,20),main="Asymmetry: Otsuki correction term",ylab="Stress tensor asymmetry [Pa]")#
#
# Stress tensors calculated uniquely by the externally visible forces are also asymmetric#
stress_tensor_asymmetry_external=stress_tensor_data$stress_tensor_from_external_forces_01-stress_tensor_data$stress_tensor_from_external_forces_10#
plot(stress_tensor_data$t,stress_tensor_asymmetry_external,type="l", ylim=c(-20,20),main="Asymmetry: Stress tensor from surface forces",ylab="Stress tensor asymmetry [Pa]")#
#
# To symmetrize the stress tensors (Nicot et. al), one can use internal acceleration#
stress_tensor_asymmetry_linear_acceleration=stress_tensor_data$stress_tensor_linear_acceleration_01-stress_tensor_data$stress_tensor_linear_acceleration_10#
plot(stress_tensor_data$t,stress_tensor_asymmetry_linear_acceleration,type="l", ylim=c(-20,20),main="Asymmetry: Linear acceleration tensor",ylab="Stress tensor asymmetry [Pa]")#
lines(stress_tensor_data$t,stress_tensor_asymmetry_external,type="l",col="red")
stress_tensor_data[1:5,]
# To symmetrize the stress tensors (Nicot et. al), one can use internal acceleration. As above, but accounting as for Love-Weber:#
stress_tensor_asymmetry_internal_torques=stress_tensor_data$stress_tensor_internal_tangential_torque_01-stress_tensor_data$stress_tensor_internal_tangential_torque_10#
plot(stress_tensor_data$t,stress_tensor_asymmetry_internal_torques,type="l", ylim=c(-20,20),main="Asymmetry: Torque correction",ylab="Stress tensor asymmetry [Pa]")#
lines(stress_tensor_data$t,stress_tensor_asymmetry_Love_Weber,type="l",col="red")
stress_tensor_asymmetry_internal_torques=stress_tensor_data$stress_tensor_internal_tangential_torque_01-stress_tensor_data$stress_tensor_internal_tangential_torque_10#
plot(stress_tensor_data$t,stress_tensor_asymmetry_internal_torques,type="l", ylim=c(-20,20),main="Asymmetry: Torque correction",ylab="Stress tensor asymmetry [Pa]")#
lines(stress_tensor_data$t,stress_tensor_asymmetry_Love_Weber,type="l",col="red")#
legend("topleft",legend=c("internal torque correction","Love-Weber"),lty=c(1,1),col=c("black","red")
)
(stress_tensor_data$stress_tensor_internal_tangential_torque_01+stress_tensor_data$stress_tensor_Love_Weber_01)[1:100]
stress_tensor_data$shear_stress_internal_stress.tensor[1:100]
# To symmetrize the stress tensors (Nicot et. al), one can use acceleration stress tensors. The importance is matching: Here, accounting done as for the external forces#
stress_tensor_asymmetry_linear_acceleration=stress_tensor_data$stress_tensor_linear_acceleration_01-stress_tensor_data$stress_tensor_linear_acceleration_10#
plot(stress_tensor_data$t,stress_tensor_asymmetry_linear_acceleration,type="l", ylim=c(-20,20),main="Asymmetry: Linear acceleration tensor",ylab="Stress tensor asymmetry [Pa]")#
lines(stress_tensor_data$t,stress_tensor_asymmetry_external,type="l",col="red")#
legend("topleft",legend=c("linear acceleration correction of total system","external force tensor"),lty=c(1,1),col=c("black","red"))
plot(stress_tensor_data$t,stress_tensor_data$shear_stress_internal_stress.tensor,type="l",ylab="Shear stress [Pa]", ylab="Time[t]")
plot(stress_tensor_data$t,stress_tensor_data$shear_stress_internal_stress.tensor,type="l",ylab="Shear stress [Pa]", xlab="Time[t]")
path=system.file("split/stress_full_python_simulation_output_example.rda",package="particleShearEvaluation")#
stress_tensor_data=read_stress_tensor_data_from_rda_file(path)
colnames(stress_tensor_data)
300e6/1000
path
e=new.env()
load(path, envir=e)
e$stress_data
negative.binomial
getAnywhere(negative.binomial)
856*2/3
857*2/3
858*2/3
library(reproducibleCalculationTools)
help(reproducibleCalculationTools)
library(reproducibleCalculationTools)
#Example 4: rda file 2 has a different entry for a numerical variable#
path_base = system.file("data_to_compare.rda",package="reproducibleCalculationTools")#
path_different_number = system.file("different_single_number.rda",package="reproducibleCalculationTools")#
comparison_with_different_number=compare_rda_contents(path_base,path_different_number)#
comparison_with_different_number
#Example 5: rda file 2 has a different entry for a numerical variable, but allow for large numerical tolerance#
path_base = system.file("data_to_compare.rda",package="reproducibleCalculationTools")#
path_different_number = system.file("different_single_number.rda",package="reproducibleCalculationTools")#
comparison_with_different_number=compare_rda_contents(path_base,path_different_number,relative_numerical_tolerance=0.2)#
comparison_with_different_number
value_comparison<-function(v1,v2,verbose=TRUE,relative_numerical_tolerance=0)#
{#
    # check dimensionality, must be the same (or possibly null)#
    if(!all(dim(v1)==dim(v2)))#
    {#
        if(verbose){cat(": unequal size")}#
        return(FALSE)#
    }#
    # Check also the length in case it's vectors#
    if(!(length(v1)==length(v2)))#
    {#
        if(verbose){cat(": unequal length")}#
        return(FALSE)#
    }#
    # Either both, or none of the two variables should be NA at the same place#
    if(any(xor(is.na(v1),is.na(v2))))#
    {#
        if(verbose){cat("Mismatch in NA elements") }#
        return(FALSE)#
    }#
    comparison=(!is.na(v1) & v1==v2)|(is.na(v1) & is.na(v2))#
    comparison_OK=all(comparison)#
    # There are sometimes issues with numerical conversions in bulk comparison, so if there are problems, compare individually#
    if(!comparison_OK)#
    {#
        # Special case: dataframes, these have different types#
        if(class(v1)=="data.frame" & class(v2)=="data.frame")#
        {#
            for(colIndex in 1:(dim(v1)[2]))#
            {#
                remaining_v1 = v1[,colIndex]#
                remaining_v2 = v2[,colIndex]#
                # Mismatch in NA values#
                if(any(xor(is.na(remaining_v1),is.na(remaining_v2))))#
                {#
                    if(verbose){cat(paste(": Not all NA values match (column ", colIndex," )",sep="")) }#
                    return(FALSE)#
                }#
                remaining_v1=remaining_v1[!is.na(remaining_v1)]#
                remaining_v2=remaining_v2[!is.na(remaining_v2)]#
                # examine the critical cases that are not anyways identical#
                # Test whether they are all the same numerically#
                if(!all(remaining_v1==remaining_v2))#
                {#
                    not_identical=!(remaining_v1==remaining_v2)#
                    remaining_v1=remaining_v1[not_identical]#
                    remaining_v2=remaining_v2[not_identical]#
                    if(relative_numerical_tolerance>0)#
                    {#
                        # The values are numeric and so no conversion is needed#
                        if(is.numeric(remaining_v1) & is.numeric(remaining_v2) )#
                        {#
                            mean_val=(remaining_v1+remaining_v2)/2#
                            deviation=abs(remaining_v2-remaining_v1)#
                            if(any(deviation>relative_numerical_tolerance))#
                            {#
                                if(verbose){cat(paste(": Numerical tolerance exceeded  (column ", colIndex," )",sep="")) }#
                                return(FALSE)#
                            }#
                        } else {#
                            # Not numeric, but is conversion possible?#
                            if(suppressWarnings(!any(is.na(as.numeric(remaining_v1)))) & suppressWarnings(!any(is.na(as.numeric(remaining_v2)))))#
                            {#
                                remaining_v1=as.numeric(remaining_v1)#
                                remaining_v2=as.numeric(remaining_v2)#
                                mean_val=(remaining_v1+remaining_v2)/2#
                                deviation=abs(remaining_v2-remaining_v1)#
                                if(any(deviation>relative_numerical_tolerance))#
                                {#
                                    if(verbose){cat(paste(": Numerical tolerance exceeded  (column ", colIndex," )",sep="")) }#
                                    return(FALSE)#
                                }#
                            } else {#
                                # We can't convert all values that were unequal, and so there must be an issue#
                                if(verbose){cat(paste(": Column with unequal values is not numeric, tolerance cannot be applied  (column ", colIndex," )",sep="")) }#
                                return(FALSE)#
                            }#
                        }#
                    } else {#
                        if(verbose){cat(paste(": Numerical tolerance 0, but non-identical values  (column ", colIndex," )",sep="")) }#
                        return(FALSE)#
                    }#
                }#
            }#
            if(verbose){cat(paste(": ",TRUE,sep=""))}#
            return(TRUE)#
        }#
        problematic_v1=v1[!comparison]#
        problematic_v2=v2[!comparison]#
        # Check the the NA entries are the same#
        NA_OK=all(is.na(problematic_v1[is.na(problematic_v2)])) &#
        all(is.na(problematic_v2[is.na(problematic_v1)]))#
        if(NA_OK){#
            # Compare the potentially problematic values directly (to exclude minor issues with numerical imprecision)#
            values_OK=all(problematic_v1[!is.na(problematic_v1)]==problematic_v2[!is.na(problematic_v2)])#
            if(values_OK)#
            {#
                comparison_OK=TRUE#
            } else {#
                # This is not a reading problem, but rather a true numerical problem. In least squares fitting, particulary, this can be an issue since the implementations are not necessary exactly the same#
                # In this case, it makes sense to allow for some relative numerical tolerance#
                if(relative_numerical_tolerance>0)#
                {#
                    numerical1=as.numeric(problematic_v1[!is.na(problematic_v1)])#
                    numerical2=as.numeric(problematic_v2[!is.na(problematic_v2)])#
                    mean_val=(numerical1+numerical2)/2#
                    deviation=abs(numerical2-numerical1)#
                    if(all(deviation<relative_numerical_tolerance))#
                    {#
                        comparison_OK=TRUE#
                    }#
                }#
            }#
        }#
    }#
    if(verbose){cat(paste(": ",comparison_OK,sep=""))}#
    return(comparison_OK)#
}
value_comparison(1,2)
value_comparison(5,5.1)
value_comparison(5,5.1,relative_numerical_tolerance=1)
value_comparison(5,5.1,relative_numerical_tolerance=0.1)
value_comparison(5,5.1,relative_numerical_tolerance=0.2)
value_comparison(5,5.1,relative_numerical_tolerance=0.05)
library(reproducibleCalculationTools)
#Example 5: rda file 2 has a different entry for a numerical variable, but allow for different levels of absolute tolerance#
path_base = system.file("data_to_compare.rda",package="reproducibleCalculationTools")#
path_different_number = system.file("different_single_number.rda",package="reproducibleCalculationTools")#
comparison_with_different_number=compare_rda_contents(path_base,path_different_number,numerical_tolerance=0.2)#
comparison_with_different_number
#Example 5: rda file 2 has a different entry for a numerical variable, but allow for different levels of absolute tolerance#
path_base = system.file("data_to_compare.rda",package="reproducibleCalculationTools")#
path_different_number = system.file("different_single_number.rda",package="reproducibleCalculationTools")#
comparison_with_different_number=compare_rda_contents(path_base,path_different_number,numerical_tolerance=0.3)#
comparison_with_different_number
load(path_base)
ls()
aNumber
load(path_different_number)
aNumber
#Example 5: rda file 2 has a different entry for a numerical variable, but allow for different levels of absolute tolerance#
path_base = system.file("data_to_compare.rda",package="reproducibleCalculationTools")#
path_different_number = system.file("different_single_number.rda",package="reproducibleCalculationTools")#
comparison_with_different_number=compare_rda_contents(path_base,path_different_number,numerical_tolerance=0.6)#
comparison_with_different_number
value_comparison<-function(v1,v2,verbose=TRUE,numerical_tolerance=0,relative_tolerance_evaluation=FALSE)#
{#
    # check dimensionality, must be the same (or possibly null)#
    if(!all(dim(v1)==dim(v2)))#
    {#
        if(verbose){cat(": unequal size")}#
        return(FALSE)#
    }#
    # Check also the length in case it's vectors#
    if(!(length(v1)==length(v2)))#
    {#
        if(verbose){cat(": unequal length")}#
        return(FALSE)#
    }#
    # Either both, or none of the two variables should be NA at the same place#
    if(any(xor(is.na(v1),is.na(v2))))#
    {#
        if(verbose){cat("Mismatch in NA elements") }#
        return(FALSE)#
    }#
    comparison=(!is.na(v1) & v1==v2)|(is.na(v1) & is.na(v2))#
    comparison_OK=all(comparison)#
    # There are sometimes issues with numerical conversions in bulk comparison, so if there are problems, compare individually#
    if(!comparison_OK)#
    {#
        # Special case: dataframes, these have different types#
        if(class(v1)=="data.frame" & class(v2)=="data.frame")#
        {#
            for(colIndex in 1:(dim(v1)[2]))#
            {#
                remaining_v1 = v1[,colIndex]#
                remaining_v2 = v2[,colIndex]#
                # Mismatch in NA values#
                if(any(xor(is.na(remaining_v1),is.na(remaining_v2))))#
                {#
                    if(verbose){cat(paste(": Not all NA values match (column ", colIndex," )",sep="")) }#
                    return(FALSE)#
                }#
                remaining_v1=remaining_v1[!is.na(remaining_v1)]#
                remaining_v2=remaining_v2[!is.na(remaining_v2)]#
                # examine the critical cases that are not anyways identical#
                # Test whether they are all the same numerically#
                if(!all(remaining_v1==remaining_v2))#
                {#
                    not_identical=!(remaining_v1==remaining_v2)#
                    remaining_v1=remaining_v1[not_identical]#
                    remaining_v2=remaining_v2[not_identical]#
                    if(numerical_tolerance>0)#
                    {#
                        # The values are numeric and so no conversion is needed#
                        if(is.numeric(remaining_v1) & is.numeric(remaining_v2) )#
                        {#
                            mean_val=(abs(remaining_v1)+abs(remaining_v2))/2#
                            deviation=abs(remaining_v2-remaining_v1)#
                            if(relative_tolerance_evaluation)#
                            {#
                                deviation=deviation/mean_val#
                            }#
                            if(any(deviation>numerical_tolerance))#
                            {#
                                if(verbose){cat(paste(": Numerical tolerance exceeded  (column ", colIndex," )",sep="")) }#
                                return(FALSE)#
                            }#
                        } else {#
                            # Not numeric, but is conversion possible?#
                            if(suppressWarnings(!any(is.na(as.numeric(remaining_v1)))) & suppressWarnings(!any(is.na(as.numeric(remaining_v2)))))#
                            {#
                                remaining_v1=as.numeric(remaining_v1)#
                                remaining_v2=as.numeric(remaining_v2)#
                                mean_val=(abs(remaining_v1)+abs(remaining_v2))/2#
                                deviation=abs(remaining_v2-remaining_v1)#
                                if(relative_tolerance_evaluation)#
                                {#
                                    deviation=deviation/mean_val#
                                }#
                                if(any(deviation>numerical_tolerance))#
                                {#
                                    if(verbose){cat(paste(": Numerical tolerance exceeded  (column ", colIndex," )",sep="")) }#
                                    return(FALSE)#
                                }#
                            } else {#
                                # We can't convert all values that were unequal, and so there must be an issue#
                                if(verbose){cat(paste(": Column with unequal values is not numeric, tolerance cannot be applied  (column ", colIndex," )",sep="")) }#
                                return(FALSE)#
                            }#
                        }#
                    } else {#
                        if(verbose){cat(paste(": Numerical tolerance 0, but non-identical values  (column ", colIndex," )",sep="")) }#
                        return(FALSE)#
                    }#
                }#
            }#
            if(verbose){cat(paste(": ",TRUE,sep=""))}#
            return(TRUE)#
        }#
        problematic_v1=v1[!comparison]#
        problematic_v2=v2[!comparison]#
        # Check the the NA entries are the same#
        NA_OK=all(is.na(problematic_v1[is.na(problematic_v2)])) &#
        all(is.na(problematic_v2[is.na(problematic_v1)]))#
        if(NA_OK){#
            # Compare the potentially problematic values directly (to exclude minor issues with numerical imprecision)#
            values_OK=all(problematic_v1[!is.na(problematic_v1)]==problematic_v2[!is.na(problematic_v2)])#
            if(values_OK)#
            {#
                comparison_OK=TRUE#
            } else {#
                # This is not a reading problem, but rather a true numerical problem. In least squares fitting, particulary, this can be an issue since the implementations are not necessary exactly the same#
                # In this case, it makes sense to allow for some relative numerical tolerance#
                if(numerical_tolerance>0)#
                {#
                    numerical1=as.numeric(problematic_v1[!is.na(problematic_v1)])#
                    numerical2=as.numeric(problematic_v2[!is.na(problematic_v2)])#
                    mean_val=(numerical1+numerical2)/2#
                    deviation=abs(numerical2-numerical1)#
                    if(all(deviation<numerical_tolerance))#
                    {#
                        comparison_OK=TRUE#
                    }#
                }#
            }#
        }#
    }#
    if(verbose){cat(paste(": ",comparison_OK,sep=""))}#
    return(comparison_OK)#
}
value_comparison(1,2,numerical_tolerance=3)
value_comparison(1,2,numerical_tolerance=1)
value_comparison(1,2,numerical_tolerance=1.1)
value_comparison(1,2,numerical_tolerance=1.0001)
#Example 5: rda file 2 has a different entry for a numerical variable, but allow for different levels of absolute tolerance#
path_base = system.file("data_to_compare.rda",package="reproducibleCalculationTools")#
path_different_number = system.file("different_single_number.rda",package="reproducibleCalculationTools")#
comparison_with_different_number=compare_rda_contents(path_base,path_different_number,numerical_tolerance=0.7)#
comparison_with_different_number
comparison_with_different_number_small_tolerance=compare_rda_contents(path_base,path_different_number,numerical_tolerance=1e-10)#
comparison_with_different_number_small_tolerance
comparison_with_different_number_large_tolerance=compare_rda_contents(path_base,path_different_number,numerical_tolerance=0.7)#
comparison_with_different_number_large_tolerance
#Example 6: rda file 2 has a different entry for a numerical variable, but allow for different levels of relative tolerance#
path_base = system.file("data_to_compare.rda",package="reproducibleCalculationTools")#
path_different_number = system.file("different_single_number.rda",package="reproducibleCalculationTools")#
comparison_with_different_number_large_tolerance=compare_rda_contents(path_base,path_different_number,numerical_tolerance=0.2,relative_tolerance_evaluation=TRUE)#
comparison_with_different_number_large_tolerance
v1=5.39
v2=6
numerical_tolerance=0.2
relative_tolerance_evaluation=TRUE
comparison=(!is.na(v1) & v1==v2)|(is.na(v1) & is.na(v2))
comparison
problematic_v1=v1[!comparison]#
        problematic_v2=v2[!comparison]
problematic
problematic_v1
library(reproducibleCalculationTools)
#Example 6: rda file 2 has a different entry for a numerical variable, but allow for different levels of relative tolerance#
path_base = system.file("data_to_compare.rda",package="reproducibleCalculationTools")#
path_different_number = system.file("different_single_number.rda",package="reproducibleCalculationTools")#
comparison_with_different_number_large_tolerance=compare_rda_contents(path_base,path_different_number,numerical_tolerance=0.2,relative_tolerance_evaluation=TRUE)#
comparison_with_different_number_large_tolerance
v1=5.39
v2=6
value_comparison<-function(v1,v2,verbose=TRUE,numerical_tolerance=0,relative_tolerance_evaluation=FALSE)#
{#
    # check dimensionality, must be the same (or possibly null)#
    if(!all(dim(v1)==dim(v2)))#
    {#
        if(verbose){cat(": unequal size")}#
        return(FALSE)#
    }#
    # Check also the length in case it's vectors#
    if(!(length(v1)==length(v2)))#
    {#
        if(verbose){cat(": unequal length")}#
        return(FALSE)#
    }#
    # Either both, or none of the two variables should be NA at the same place#
    if(any(xor(is.na(v1),is.na(v2))))#
    {#
        if(verbose){cat("Mismatch in NA elements") }#
        return(FALSE)#
    }#
    comparison=(!is.na(v1) & v1==v2)|(is.na(v1) & is.na(v2))#
    comparison_OK=all(comparison)#
    # There are sometimes issues with numerical conversions in bulk comparison, so if there are problems, compare individually#
    if(!comparison_OK)#
    {#
        # Special case: dataframes, these have different types#
        if(class(v1)=="data.frame" & class(v2)=="data.frame")#
        {#
            for(colIndex in 1:(dim(v1)[2]))#
            {#
                remaining_v1 = v1[,colIndex]#
                remaining_v2 = v2[,colIndex]#
                # Mismatch in NA values#
                if(any(xor(is.na(remaining_v1),is.na(remaining_v2))))#
                {#
                    if(verbose){cat(paste(": Not all NA values match (column ", colIndex," )",sep="")) }#
                    return(FALSE)#
                }#
                remaining_v1=remaining_v1[!is.na(remaining_v1)]#
                remaining_v2=remaining_v2[!is.na(remaining_v2)]#
                # examine the critical cases that are not anyways identical#
                # Test whether they are all the same numerically#
                if(!all(remaining_v1==remaining_v2))#
                {#
                    not_identical=!(remaining_v1==remaining_v2)#
                    remaining_v1=remaining_v1[not_identical]#
                    remaining_v2=remaining_v2[not_identical]#
                    if(numerical_tolerance>0)#
                    {#
                        # The values are numeric and so no conversion is needed#
                        if(is.numeric(remaining_v1) & is.numeric(remaining_v2) )#
                        {#
                            mean_val=(abs(remaining_v1)+abs(remaining_v2))/2#
                            deviation=abs(remaining_v2-remaining_v1)#
                            if(relative_tolerance_evaluation)#
                            {#
                                deviation=deviation/mean_val#
                            }#
                            if(any(deviation>numerical_tolerance))#
                            {#
                                if(verbose){cat(paste(": Numerical tolerance exceeded  (column ", colIndex," )",sep="")) }#
                                return(FALSE)#
                            }#
                        } else {#
                            # Not numeric, but is conversion possible?#
                            if(suppressWarnings(!any(is.na(as.numeric(remaining_v1)))) & suppressWarnings(!any(is.na(as.numeric(remaining_v2)))))#
                            {#
                                remaining_v1=as.numeric(remaining_v1)#
                                remaining_v2=as.numeric(remaining_v2)#
                                mean_val=(abs(remaining_v1)+abs(remaining_v2))/2#
                                deviation=abs(remaining_v2-remaining_v1)#
                                if(relative_tolerance_evaluation)#
                                {#
                                    deviation=deviation/mean_val#
                                }#
                                if(any(deviation>numerical_tolerance))#
                                {#
                                    if(verbose){cat(paste(": Numerical tolerance exceeded  (column ", colIndex," )",sep="")) }#
                                    return(FALSE)#
                                }#
                            } else {#
                                # We can't convert all values that were unequal, and so there must be an issue#
                                if(verbose){cat(paste(": Column with unequal values is not numeric, tolerance cannot be applied  (column ", colIndex," )",sep="")) }#
                                return(FALSE)#
                            }#
                        }#
                    } else {#
                        if(verbose){cat(paste(": Numerical tolerance 0, but non-identical values  (column ", colIndex," )",sep="")) }#
                        return(FALSE)#
                    }#
                }#
            }#
            if(verbose){cat(paste(": ",TRUE,sep=""))}#
            return(TRUE)#
        }#
        problematic_v1=v1[!comparison]#
        problematic_v2=v2[!comparison]#
        # Check the the NA entries are the same#
        NA_OK=all(is.na(problematic_v1[is.na(problematic_v2)])) &#
        all(is.na(problematic_v2[is.na(problematic_v1)]))#
        if(NA_OK){#
            # Compare the potentially problematic values directly (to exclude minor issues with numerical imprecision)#
            values_OK=all(problematic_v1[!is.na(problematic_v1)]==problematic_v2[!is.na(problematic_v2)])#
            if(values_OK)#
            {#
                comparison_OK=TRUE#
            } else {#
                # This is not a reading problem, but rather a true numerical problem. In least squares fitting, particulary, this can be an issue since the implementations are not necessary exactly the same#
                # In this case, it makes sense to allow for some relative numerical tolerance#
                if(numerical_tolerance>0)#
                {#
                    numerical1=as.numeric(problematic_v1[!is.na(problematic_v1)])#
                    numerical2=as.numeric(problematic_v2[!is.na(problematic_v2)])#
                    mean_val=(abs(numerical1)+abs(numerical2))/2#
                    deviation=abs(numerical2-numerical1)#
                    if(relative_tolerance_evaluation)#
                    {#
                        deviation=deviation/mean_val#
                    }#
                    if(all(deviation<numerical_tolerance))#
                    {#
                        comparison_OK=TRUE#
                    }#
                }#
            }#
        }#
    }#
    if(verbose){cat(paste(": ",comparison_OK,sep=""))}#
    return(comparison_OK)#
}
numerical_tolerance=0.2
verbose=TRUE
relative_tolerance_evaluation=TRUE
!all(dim(v1)==dim(v2))
!(length(v1)==length(v2))
any(xor(is.na(v1),is.na(v2)))
comparison=(!is.na(v1) & v1==v2)|(is.na(v1) & is.na(v2))
comparison
problematic_v1=v1[!comparison]#
        problematic_v2=v2[!comparison]#
        # Check the the NA entries are the same#
        NA_OK=all(is.na(problematic_v1[is.na(problematic_v2)])) &#
        all(is.na(problematic_v2[is.na(problematic_v1)]))
NA_OK
values_OK=all(problematic_v1[!is.na(problematic_v1)]==problematic_v2[!is.na(problematic_v2)])
values_OL
values_OK
numerical_tolerance>0
numerical1=as.numeric(problematic_v1[!is.na(problematic_v1)])#
                    numerical2=as.numeric(problematic_v2[!is.na(problematic_v2)])#
                    mean_val=(abs(numerical1)+abs(numerical2))/2#
                    deviation=abs(numerical2-numerical1)#
                    if(relative_tolerance_evaluation)#
                    {#
                        deviation=deviation/mean_val#
                    }
deviation
all(deviation<numerical_tolerance)
value_comparison(5.39,6)
value_comparison(5.39,6,numerical_tolerance=0.7)
value_comparison(5.39,6,numerical_tolerance=0.2)
value_comparison(5.39,6,numerical_tolerance=0.2,relative_tolerance_evaluation=TRUE)
library(reproducibleCalculationTools)
#Example 6: rda file 2 has a different entry for a numerical variable, but allow for different levels of relative tolerance#
path_base = system.file("data_to_compare.rda",package="reproducibleCalculationTools")#
path_different_number = system.file("different_single_number.rda",package="reproducibleCalculationTools")#
comparison_with_different_number_large_tolerance=compare_rda_contents(path_base,path_different_number,numerical_tolerance=0.2,relative_tolerance_evaluation=TRUE)#
comparison_with_different_number_large_tolerance
load(paht_base)
load(path_base)
aNumber
load(path_different_number)
aNumber
library(reproducibleCalculationTools)
#Example 6: rda file 2 has a different entry for a numerical variable, but allow for different levels of relative tolerance#
path_base = system.file("data_to_compare.rda",package="reproducibleCalculationTools")#
path_different_number = system.file("different_single_number.rda",package="reproducibleCalculationTools")#
comparison_with_different_number_large_tolerance=compare_rda_contents(path_base,path_different_number,numerical_tolerance=0.2,relative_tolerance_evaluation=TRUE)#
comparison_with_different_number_large_tolerance
#Example 6: rda file 2 has a different entry for a numerical variable, but allow for different levels of relative tolerance#
path_base = system.file("data_to_compare.rda",package="reproducibleCalculationTools")#
path_different_number = system.file("different_single_number.rda",package="reproducibleCalculationTools")#
comparison_with_different_number_large_tolerance=compare_rda_contents(path_base,path_different_number,numerical_tolerance=0.2,relative_tolerance_evaluation=TRUE)#
comparison_with_different_number_large_tolerance#
#
comparison_with_different_number_small_tolerance=compare_rda_contents(path_base,path_different_number,numerical_tolerance=1e-6,relative_tolerance_evaluation=TRUE)#
comparison_with_different_number_small_tolerance
load(path_base)
ls()
aString
aString="that not"
save(file="different_string.rda",list=c("aDataframe","aNumber","aString"))
aDataframe
load(path_base)
aDataframe
aDataframe[5,1]
aDataframe[5,1]="not the same"
save(file="string_change_in_dataframe.rda",list=c("aDataframe","aNumber","aString"))
load(path_base)
aDataframe
aDataframe$extracolumn=NA
aDataframe
save(file="extra_column_in_dataframe.rda",list=c("aDataframe","aNumber","aString"))
